{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cf3c31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Analysis\\NeuroPred\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "print(module_path)\n",
    "sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b576fc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\np_test\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import clip\n",
    "import timm\n",
    "import open_clip\n",
    "import torchvision.models as models\n",
    "\n",
    "from NeuroPredictor.FeatExtractor import (\n",
    "    TimmFeatureExtractor,\n",
    "    TorchvisionFeatureExtractor,\n",
    "    CLIPFeatureExtractor,\n",
    "    OpenCLIPFeatureExtractor\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9256d123",
   "metadata": {},
   "source": [
    "#### Get available models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb3bd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['coca_base', 'coca_roberta-ViT-B-32', 'coca_ViT-B-32', 'coca_ViT-L-14', 'convnext_base', 'convnext_base_w', 'convnext_base_w_320', 'convnext_large', 'convnext_large_d', 'convnext_large_d_320', 'convnext_small', 'convnext_tiny', 'convnext_xlarge', 'convnext_xxlarge', 'convnext_xxlarge_320', 'EVA01-g-14', 'EVA01-g-14-plus', 'EVA02-B-16', 'EVA02-E-14', 'EVA02-E-14-plus', 'EVA02-L-14', 'EVA02-L-14-336', 'MobileCLIP-B', 'MobileCLIP-S1', 'MobileCLIP-S2', 'mt5-base-ViT-B-32', 'mt5-xl-ViT-H-14', 'nllb-clip-base', 'nllb-clip-base-siglip', 'nllb-clip-large', 'nllb-clip-large-siglip', 'RN50', 'RN50-quickgelu', 'RN50x4', 'RN50x4-quickgelu', 'RN50x16', 'RN50x16-quickgelu', 'RN50x64', 'RN50x64-quickgelu', 'RN101', 'RN101-quickgelu', 'roberta-ViT-B-32', 'swin_base_patch4_window7_224', 'ViT-B-16', 'ViT-B-16-plus', 'ViT-B-16-plus-240', 'ViT-B-16-quickgelu', 'ViT-B-16-SigLIP', 'ViT-B-16-SigLIP2', 'ViT-B-16-SigLIP2-256', 'ViT-B-16-SigLIP2-384', 'ViT-B-16-SigLIP2-512', 'ViT-B-16-SigLIP-256', 'ViT-B-16-SigLIP-384', 'ViT-B-16-SigLIP-512', 'ViT-B-16-SigLIP-i18n-256', 'ViT-B-32', 'ViT-B-32-256', 'ViT-B-32-plus-256', 'ViT-B-32-quickgelu', 'ViT-B-32-SigLIP2-256', 'ViT-bigG-14', 'ViT-bigG-14-CLIPA', 'ViT-bigG-14-CLIPA-336', 'ViT-bigG-14-quickgelu', 'ViT-e-14', 'ViT-g-14', 'ViT-gopt-16-SigLIP2-256', 'ViT-gopt-16-SigLIP2-384', 'ViT-H-14', 'ViT-H-14-378', 'ViT-H-14-378-quickgelu', 'ViT-H-14-CLIPA', 'ViT-H-14-CLIPA-336', 'ViT-H-14-quickgelu', 'ViT-H-16', 'ViT-L-14', 'ViT-L-14-280', 'ViT-L-14-336', 'ViT-L-14-336-quickgelu', 'ViT-L-14-CLIPA', 'ViT-L-14-CLIPA-336', 'ViT-L-14-quickgelu', 'ViT-L-16', 'ViT-L-16-320', 'ViT-L-16-SigLIP2-256', 'ViT-L-16-SigLIP2-384', 'ViT-L-16-SigLIP2-512', 'ViT-L-16-SigLIP-256', 'ViT-L-16-SigLIP-384', 'ViT-M-16', 'ViT-M-16-alt', 'ViT-M-32', 'ViT-M-32-alt', 'ViT-S-16', 'ViT-S-16-alt', 'ViT-S-32', 'ViT-S-32-alt', 'ViT-SO400M-14-SigLIP', 'ViT-SO400M-14-SigLIP2', 'ViT-SO400M-14-SigLIP2-378', 'ViT-SO400M-14-SigLIP-378', 'ViT-SO400M-14-SigLIP-384', 'ViT-SO400M-16-SigLIP2-256', 'ViT-SO400M-16-SigLIP2-384', 'ViT-SO400M-16-SigLIP2-512', 'ViT-SO400M-16-SigLIP-i18n-256', 'vit_medium_patch16_gap_256', 'vit_relpos_medium_patch16_cls_224', 'ViTamin-B', 'ViTamin-B-LTT', 'ViTamin-L', 'ViTamin-L2', 'ViTamin-L2-256', 'ViTamin-L2-336', 'ViTamin-L2-384', 'ViTamin-L-256', 'ViTamin-L-336', 'ViTamin-L-384', 'ViTamin-S', 'ViTamin-S-LTT', 'ViTamin-XL-256', 'ViTamin-XL-336', 'ViTamin-XL-384', 'xlm-roberta-base-ViT-B-32', 'xlm-roberta-large-ViT-H-14']\n"
     ]
    }
   ],
   "source": [
    "backbone_type = 'openclip' # 'timm', 'torchvision', 'clip', 'openclip'\n",
    "if backbone_type == 'timm':\n",
    "    model_list = timm.list_models()\n",
    "elif backbone_type == 'torchvision':\n",
    "    model_list = models.list_models()\n",
    "elif backbone_type == 'clip':\n",
    "    model_list = clip.available_models()\n",
    "elif backbone_type == 'openclip':\n",
    "    model_list = open_clip.list_models()\n",
    "\n",
    "print(model_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95fcfc5",
   "metadata": {},
   "source": [
    "#### Get available layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e46e4559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['patch_embed.proj', 'patch_embed.norm', 'pos_drop', 'patch_drop', 'norm_pre', 'blocks.0.norm1', 'blocks.0.attn.qkv', 'blocks.0.attn.q_norm', 'blocks.0.attn.k_norm', 'blocks.0.attn.attn_drop', 'blocks.0.attn.norm', 'blocks.0.attn.proj', 'blocks.0.attn.proj_drop', 'blocks.0.ls1', 'blocks.0.drop_path1', 'blocks.0.norm2', 'blocks.0.mlp.fc1', 'blocks.0.mlp.act', 'blocks.0.mlp.drop1', 'blocks.0.mlp.norm', 'blocks.0.mlp.fc2', 'blocks.0.mlp.drop2', 'blocks.0.ls2', 'blocks.0.drop_path2', 'blocks.1.norm1', 'blocks.1.attn.qkv', 'blocks.1.attn.q_norm', 'blocks.1.attn.k_norm', 'blocks.1.attn.attn_drop', 'blocks.1.attn.norm', 'blocks.1.attn.proj', 'blocks.1.attn.proj_drop', 'blocks.1.ls1', 'blocks.1.drop_path1', 'blocks.1.norm2', 'blocks.1.mlp.fc1', 'blocks.1.mlp.act', 'blocks.1.mlp.drop1', 'blocks.1.mlp.norm', 'blocks.1.mlp.fc2', 'blocks.1.mlp.drop2', 'blocks.1.ls2', 'blocks.1.drop_path2', 'blocks.2.norm1', 'blocks.2.attn.qkv', 'blocks.2.attn.q_norm', 'blocks.2.attn.k_norm', 'blocks.2.attn.attn_drop', 'blocks.2.attn.norm', 'blocks.2.attn.proj', 'blocks.2.attn.proj_drop', 'blocks.2.ls1', 'blocks.2.drop_path1', 'blocks.2.norm2', 'blocks.2.mlp.fc1', 'blocks.2.mlp.act', 'blocks.2.mlp.drop1', 'blocks.2.mlp.norm', 'blocks.2.mlp.fc2', 'blocks.2.mlp.drop2', 'blocks.2.ls2', 'blocks.2.drop_path2', 'blocks.3.norm1', 'blocks.3.attn.qkv', 'blocks.3.attn.q_norm', 'blocks.3.attn.k_norm', 'blocks.3.attn.attn_drop', 'blocks.3.attn.norm', 'blocks.3.attn.proj', 'blocks.3.attn.proj_drop', 'blocks.3.ls1', 'blocks.3.drop_path1', 'blocks.3.norm2', 'blocks.3.mlp.fc1', 'blocks.3.mlp.act', 'blocks.3.mlp.drop1', 'blocks.3.mlp.norm', 'blocks.3.mlp.fc2', 'blocks.3.mlp.drop2', 'blocks.3.ls2', 'blocks.3.drop_path2', 'blocks.4.norm1', 'blocks.4.attn.qkv', 'blocks.4.attn.q_norm', 'blocks.4.attn.k_norm', 'blocks.4.attn.attn_drop', 'blocks.4.attn.norm', 'blocks.4.attn.proj', 'blocks.4.attn.proj_drop', 'blocks.4.ls1', 'blocks.4.drop_path1', 'blocks.4.norm2', 'blocks.4.mlp.fc1', 'blocks.4.mlp.act', 'blocks.4.mlp.drop1', 'blocks.4.mlp.norm', 'blocks.4.mlp.fc2', 'blocks.4.mlp.drop2', 'blocks.4.ls2', 'blocks.4.drop_path2', 'blocks.5.norm1', 'blocks.5.attn.qkv', 'blocks.5.attn.q_norm', 'blocks.5.attn.k_norm', 'blocks.5.attn.attn_drop', 'blocks.5.attn.norm', 'blocks.5.attn.proj', 'blocks.5.attn.proj_drop', 'blocks.5.ls1', 'blocks.5.drop_path1', 'blocks.5.norm2', 'blocks.5.mlp.fc1', 'blocks.5.mlp.act', 'blocks.5.mlp.drop1', 'blocks.5.mlp.norm', 'blocks.5.mlp.fc2', 'blocks.5.mlp.drop2', 'blocks.5.ls2', 'blocks.5.drop_path2', 'blocks.6.norm1', 'blocks.6.attn.qkv', 'blocks.6.attn.q_norm', 'blocks.6.attn.k_norm', 'blocks.6.attn.attn_drop', 'blocks.6.attn.norm', 'blocks.6.attn.proj', 'blocks.6.attn.proj_drop', 'blocks.6.ls1', 'blocks.6.drop_path1', 'blocks.6.norm2', 'blocks.6.mlp.fc1', 'blocks.6.mlp.act', 'blocks.6.mlp.drop1', 'blocks.6.mlp.norm', 'blocks.6.mlp.fc2', 'blocks.6.mlp.drop2', 'blocks.6.ls2', 'blocks.6.drop_path2', 'blocks.7.norm1', 'blocks.7.attn.qkv', 'blocks.7.attn.q_norm', 'blocks.7.attn.k_norm', 'blocks.7.attn.attn_drop', 'blocks.7.attn.norm', 'blocks.7.attn.proj', 'blocks.7.attn.proj_drop', 'blocks.7.ls1', 'blocks.7.drop_path1', 'blocks.7.norm2', 'blocks.7.mlp.fc1', 'blocks.7.mlp.act', 'blocks.7.mlp.drop1', 'blocks.7.mlp.norm', 'blocks.7.mlp.fc2', 'blocks.7.mlp.drop2', 'blocks.7.ls2', 'blocks.7.drop_path2', 'blocks.8.norm1', 'blocks.8.attn.qkv', 'blocks.8.attn.q_norm', 'blocks.8.attn.k_norm', 'blocks.8.attn.attn_drop', 'blocks.8.attn.norm', 'blocks.8.attn.proj', 'blocks.8.attn.proj_drop', 'blocks.8.ls1', 'blocks.8.drop_path1', 'blocks.8.norm2', 'blocks.8.mlp.fc1', 'blocks.8.mlp.act', 'blocks.8.mlp.drop1', 'blocks.8.mlp.norm', 'blocks.8.mlp.fc2', 'blocks.8.mlp.drop2', 'blocks.8.ls2', 'blocks.8.drop_path2', 'blocks.9.norm1', 'blocks.9.attn.qkv', 'blocks.9.attn.q_norm', 'blocks.9.attn.k_norm', 'blocks.9.attn.attn_drop', 'blocks.9.attn.norm', 'blocks.9.attn.proj', 'blocks.9.attn.proj_drop', 'blocks.9.ls1', 'blocks.9.drop_path1', 'blocks.9.norm2', 'blocks.9.mlp.fc1', 'blocks.9.mlp.act', 'blocks.9.mlp.drop1', 'blocks.9.mlp.norm', 'blocks.9.mlp.fc2', 'blocks.9.mlp.drop2', 'blocks.9.ls2', 'blocks.9.drop_path2', 'blocks.10.norm1', 'blocks.10.attn.qkv', 'blocks.10.attn.q_norm', 'blocks.10.attn.k_norm', 'blocks.10.attn.attn_drop', 'blocks.10.attn.norm', 'blocks.10.attn.proj', 'blocks.10.attn.proj_drop', 'blocks.10.ls1', 'blocks.10.drop_path1', 'blocks.10.norm2', 'blocks.10.mlp.fc1', 'blocks.10.mlp.act', 'blocks.10.mlp.drop1', 'blocks.10.mlp.norm', 'blocks.10.mlp.fc2', 'blocks.10.mlp.drop2', 'blocks.10.ls2', 'blocks.10.drop_path2', 'blocks.11.norm1', 'blocks.11.attn.qkv', 'blocks.11.attn.q_norm', 'blocks.11.attn.k_norm', 'blocks.11.attn.attn_drop', 'blocks.11.attn.norm', 'blocks.11.attn.proj', 'blocks.11.attn.proj_drop', 'blocks.11.ls1', 'blocks.11.drop_path1', 'blocks.11.norm2', 'blocks.11.mlp.fc1', 'blocks.11.mlp.act', 'blocks.11.mlp.drop1', 'blocks.11.mlp.norm', 'blocks.11.mlp.fc2', 'blocks.11.mlp.drop2', 'blocks.11.ls2', 'blocks.11.drop_path2', 'norm', 'fc_norm', 'head_drop', 'head', 'blocks.0', 'blocks.1', 'blocks.2', 'blocks.3', 'blocks.4', 'blocks.5', 'blocks.6', 'blocks.7', 'blocks.8', 'blocks.9', 'blocks.10', 'blocks.11']\n"
     ]
    }
   ],
   "source": [
    "backbone_type = 'timm'\n",
    "model_name = 'vit_base_patch16_clip_224.laion2b'\n",
    "\n",
    "if backbone_type == 'timm':\n",
    "    model = TimmFeatureExtractor(model_name=model_name)\n",
    "elif backbone_type == 'torchvision':\n",
    "    model = TorchvisionFeatureExtractor(model_name=model_name)\n",
    "elif backbone_type == 'clip':\n",
    "    model = CLIPFeatureExtractor(model_name=model_name)\n",
    "elif backbone_type == 'openclip':\n",
    "    model = OpenCLIPFeatureExtractor(model_name=model_name)\n",
    "\n",
    "print(model.list_hookable_layers())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fade35e",
   "metadata": {},
   "source": [
    "#### Get the shape of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ce66a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patch_embed.proj: (1, 768, 14, 14)\n",
      "blocks.0.norm1: (1, 197, 768)\n",
      "blocks.0.attn.qkv: (1, 197, 2304)\n",
      "blocks.11: (1, 197, 768)\n",
      "norm: (1, 197, 768)\n"
     ]
    }
   ],
   "source": [
    "extractor = TimmFeatureExtractor(model_name='vit_base_patch16_clip_224.laion2b')\n",
    "layers = extractor.list_hookable_layers()\n",
    "selected_layers = ['patch_embed.proj', 'blocks.0.norm1', 'blocks.0.attn.qkv', 'blocks.11', 'norm']\n",
    "shapes = extractor.get_feature_shapes(selected_layers)\n",
    "\n",
    "for name, shape in shapes.items():\n",
    "    print(f\"{name}: {shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "np_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
